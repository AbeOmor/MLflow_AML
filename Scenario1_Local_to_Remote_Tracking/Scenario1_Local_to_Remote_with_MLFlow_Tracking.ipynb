{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 1: Local to Remote with MLFlow (Tracking)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)\tUser trains locally using MLFlow using MLFlow logging / autologging\r\n",
        "\r\n",
        "2)\tMove to AML by setting the tracking URI in the backend (not in my training code), packaging as a project and using the AzureML CLIv2 or MLFlow CLI. The user doesnâ€™t have to change their training or scoring code.\r\n",
        "\r\n",
        "    a.\tUsers set MLFLOW_TRACKING_URI via CLI\r\n",
        "    b.\tUser should be able to run same code\r\n",
        "    c.\tThe user can run that same training script locally and still have everything tracked in AML without updating code\r\n",
        "\r\n",
        "3)\tAll AML parameters, metrics, models and logged artifacts should show up in AML run history\r\n",
        "\r\n",
        "**NOTE** This only works if the user has set an experiment in their code, if not it break. We need to be able to set a default experiment for the user with now experiment set."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User trains locally using MLFlow using MLFlow logging / autologging"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Microsoft. All rights reserved.\r\n",
        "# Licensed under the MIT license.\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.datasets import load_diabetes\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "with mlflow.start_run():\r\n",
        "    X, y = load_diabetes(return_X_y=True)\r\n",
        "    columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\r\n",
        "    data = {\r\n",
        "        \"train\": {\"X\": X_train, \"y\": y_train},\r\n",
        "        \"test\": {\"X\": X_test, \"y\": y_test}}\r\n",
        "\r\n",
        "    mlflow.log_metric(\"Training samples\", len(data['train']['X']))\r\n",
        "    mlflow.log_metric(\"Test samples\", len(data['test']['X']))\r\n",
        "\r\n",
        "    # Log the algorithm parameter alpha to the run\r\n",
        "    mlflow.log_metric('alpha', 0.03)\r\n",
        "    # Create, fit, and test the scikit-learn Ridge regression model\r\n",
        "    regression_model = Ridge(alpha=0.03)\r\n",
        "    regression_model.fit(data['train']['X'], data['train']['y'])\r\n",
        "    preds = regression_model.predict(data['test']['X'])\r\n",
        "\r\n",
        "    # Log mean squared error\r\n",
        "    print('Mean Squared Error is', mean_squared_error(data['test']['y'], preds))\r\n",
        "    mlflow.log_metric('mse', mean_squared_error(data['test']['y'], preds))\r\n",
        "\r\n",
        "    # Save the model to the outputs directory for capture\r\n",
        "    mlflow.sklearn.log_model(regression_model, \"model\")\r\n",
        "\r\n",
        "    # Plot actuals vs predictions and save the plot within the run\r\n",
        "    fig = plt.figure(1)\r\n",
        "    idx = np.argsort(data['test']['y'])\r\n",
        "    plt.plot(data['test']['y'][idx], preds[idx])\r\n",
        "    fig.savefig(\"actuals_vs_predictions.png\")\r\n",
        "    mlflow.log_artifact(\"actuals_vs_predictions.png\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mean Squared Error is 3424.900315896017\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641327187567
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look for the **/mlruns** folder in your current directory to find the run details"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move to AML by setting the tracking URI in the backend (not in my training code), and using MLFlow CLI. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The Compute instance team will be added in Tracking_URI to every Compute Instance in the future"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!az extension add -n ml -y "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[K - Searching ..\r\u001b[93mExtension 'ml' is already installed.\u001b[0m\r\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!az login"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\r\n",
        "\r\n",
        "#Get MLFLow UI through the Azure ML CLI v2 and convert to string\r\n",
        "MLFLOW_TRACKING_URI = subprocess.run([\"az\", \"ml\", \"workspace\", \"show\", \"--query\", \"mlflow_tracking_uri\", \"-o\", \"tsv\"], stdout=subprocess.PIPE, text=True)\r\n",
        "MLFLOW_TRACKING_URI = str(MLFLOW_TRACKING_URI.stdout).strip()\r\n",
        "\r\n",
        "## Make sure the MLFLow URI looks something like this: \r\n",
        "## azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/<Sub-ID>/resourceGroups/<RG>/providers/Microsoft.MachineLearningServices/workspaces/<WS>\r\n",
        "print(\"MLFlow Tracking URI:\", MLFLOW_TRACKING_URI)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING: Command group 'ml workspace' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLFlow Tracking URI: azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourceGroups/osomorog/providers/Microsoft.MachineLearningServices/workspaces/mlflowworkspace\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641327257701
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set the MLFLOW TRACKING URI\r\n",
        "import mlflow\r\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641327267302
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run again with AzureML as Tracking Server"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: This only works if the user has set an experiment in their code, if not it break. We need to be able to set a default experiment for the user with now experiment set. A default experiment flow will be avaible in future release"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Microsoft. All rights reserved.\r\n",
        "# Licensed under the MIT license.\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.datasets import load_diabetes\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "## User currently needs to add an experiment name. Should not be neccesary in a future relase\r\n",
        "mlflow.set_experiment(\"test-abe\")\r\n",
        "########\r\n",
        "\r\n",
        "with mlflow.start_run():\r\n",
        "    X, y = load_diabetes(return_X_y=True)\r\n",
        "    columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\r\n",
        "    data = {\r\n",
        "        \"train\": {\"X\": X_train, \"y\": y_train},\r\n",
        "        \"test\": {\"X\": X_test, \"y\": y_test}}\r\n",
        "\r\n",
        "    mlflow.log_metric(\"Training samples\", len(data['train']['X']))\r\n",
        "    mlflow.log_metric(\"Test samples\", len(data['test']['X']))\r\n",
        "\r\n",
        "    # Log the algorithm parameter alpha to the run\r\n",
        "    mlflow.log_metric('alpha', 0.03)\r\n",
        "    # Create, fit, and test the scikit-learn Ridge regression model\r\n",
        "    regression_model = Ridge(alpha=0.03)\r\n",
        "    regression_model.fit(data['train']['X'], data['train']['y'])\r\n",
        "    preds = regression_model.predict(data['test']['X'])\r\n",
        "\r\n",
        "    # Log mean squared error\r\n",
        "    print('Mean Squared Error is', mean_squared_error(data['test']['y'], preds))\r\n",
        "    mlflow.log_metric('mse', mean_squared_error(data['test']['y'], preds))\r\n",
        "\r\n",
        "    # Save the model to the outputs directory for capture\r\n",
        "    mlflow.sklearn.log_model(regression_model, \"model\")\r\n",
        "\r\n",
        "    # Plot actuals vs predictions and save the plot within the run\r\n",
        "    fig = plt.figure(1)\r\n",
        "    idx = np.argsort(data['test']['y'])\r\n",
        "    plt.plot(data['test']['y'][idx], preds[idx])\r\n",
        "    fig.savefig(\"actuals_vs_predictions.png\")\r\n",
        "    mlflow.log_artifact(\"actuals_vs_predictions.png\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mean Squared Error is 3424.900315896017\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641327280553
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the Experiments page in AML to find the run details"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}