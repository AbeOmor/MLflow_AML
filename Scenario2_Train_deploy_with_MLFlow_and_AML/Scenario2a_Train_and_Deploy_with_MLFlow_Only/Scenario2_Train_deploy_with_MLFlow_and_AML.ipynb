{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 2: Train and deploy with MLFlow and AML\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)\tTrain baseline model and log / autolog with MLFlow and submit job with AML CLI/MLFLow CLI\r\n",
        "\r\n",
        "2)\tTest model locally with v2 CLI and manually validate results\r\n",
        "\r\n",
        "3)\tRegister the model from the run \r\n",
        "\r\n",
        "4)\t{Optional} Change the model stage to “Production” and discuss with team before deploying to production (**NOTE:** Not fully integrate in AML UI yet)\r\n",
        "    \r\n",
        "5)\tAfter user is satisfied with the model, deploy model on AML to an endpoint and use endpoint to predict all the result from a dataset. (**NOTE: ** TensorSpec not supported yet)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move to AML by setting the tracking URI in the backend (not in my training code), and using MLFlow CLI. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az extension add -n ml -y "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az login"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "#Get MLFLow UI through the Azure ML CLI v2 and convert to string\n",
        "MLFLOW_TRACKING_URI = subprocess.run([\"az\", \"ml\", \"workspace\", \"show\", \"--query\", \"mlflow_tracking_uri\", \"-o\", \"tsv\"], stdout=subprocess.PIPE, text=True)\n",
        "MLFLOW_TRACKING_URI = str(MLFLOW_TRACKING_URI.stdout).strip()\n",
        "\n",
        "## Make sure the MLFLow URI looks something like this: \n",
        "## azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/<Sub-ID>/resourceGroups/<RG>/providers/Microsoft.MachineLearningServices/workspaces/<WS>\n",
        "print(\"MLFlow Tracking URI:\", MLFLOW_TRACKING_URI)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814372961
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set the MLFLOW TRACKING URI\n",
        "import mlflow\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814376723
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train baseline model and log / autolog with MLFlow and submit job with MLFLow CLI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"USE_CONDA\": False}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638814395728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "local_env_run = mlflow.projects.run(uri=\"simple_project\", \n",
        "                                    parameters={\"alpha\":0.2},\n",
        "                                    experiment_name=\"Scenario2_project\",\n",
        "                                    backend = \"azureml\",\n",
        "                                    use_conda=True,\n",
        "                                    backend_config = backend_config, \n",
        "                                    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638814442150
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download or retrieve the model from the run for testing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.entities import ViewType\n",
        "experiment_name=\"Scenario2_project\"\n",
        "current_experiment=mlflow.get_experiment_by_name(experiment_name)\n",
        "runs = mlflow.search_runs(experiment_ids=current_experiment.experiment_id, run_view_type=ViewType.ALL)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814443176
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_run_id = runs.tail(1)[\"run_id\"].tolist()[0]\r\n",
        "last_run_id"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814445701
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and Load Test Data from JSON"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.tracking.client import MlflowClient\n",
        "client = MlflowClient()\n",
        "client.download_artifacts(last_run_id,\"model/input_example.json\",\".\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814448397
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "with open('model/input_example.json') as f:\r\n",
        "   sample_data = json.load(f)\r\n",
        "\r\n",
        "#columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\r\n",
        "print(sample_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814450974
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"model\"\r\n",
        "artifact_uri = \"runs:/{}/{}\".format(last_run_id,model_path)\r\n",
        "model = mlflow.sklearn.load_model(artifact_uri)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638814530068
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(sample_data[\"inputs\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814532701
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register Model with MLFLow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.register_model(artifact_uri,\"scenario2model\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638814545902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Transistion Model to Production Stage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "client = MlflowClient()\r\n",
        "client.transition_model_version_stage(\r\n",
        "    name=\"scenario2model\",\r\n",
        "    version=1,\r\n",
        "    stage=\"Production\"\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638588491686
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List Model details"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\r\n",
        "client = MlflowClient()\r\n",
        "for mv in client.search_model_versions(\"name='scenario2model'\"):\r\n",
        "    pprint(dict(mv), indent=4)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638814606620
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy to AzureML's MIR with MLFLow\r\n",
        "As of Dec 2021, Not Support:\r\n",
        "- TensorSpec for Deployment in AML is not fully supported\r\n",
        "- Endpoints are not fully supported with MLFlow deployment, there is a 1:1 relationship between deployment and endpoint. MLFlow needs to support the ability to deploy multiple models to the 1 endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.deployments import get_deploy_client\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# set the tracking uri as the deployment client\n",
        "client = get_deploy_client(mlflow.get_tracking_uri())\n",
        "\n",
        "# set the model path \n",
        "# model_path = \"model\"\n",
        "# run_id= \"13c5faef-788f-439d-ba6c-cb8d280e708d\"\n",
        "\n",
        "# Retrieve model from registry\n",
        "model_name = \"scenario2model\"\n",
        "model_version = 1\n",
        "model_uri = 'models:/{}/{}'.format(model_name, model_version)\n",
        "\n",
        "# define the model path and the name is the service name\n",
        "# the model gets registered automatically and a name is autogenerated using the \"name\" parameter below \n",
        "# set the deployment config\n",
        "deploy_path = \"deployment_config_v2.json\"\n",
        "test_config = {'deploy-config-file': deploy_path}\n",
        "\n",
        "client.create_deployment(model_uri=model_uri,\n",
        "                         config=test_config,\n",
        "                         name=\"mlflowscenario3\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test endpoint with MLFlow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find code snippet below, in the Endpoint UI in AzureML and navigate to the Consume Tab for the Endpoint you just deployed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = sample_data\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'https://mlflowscenario2.westus.inference.ml.azure.com/score'\r\n",
        "api_key = '' # Replace this with the API key for the web service\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}