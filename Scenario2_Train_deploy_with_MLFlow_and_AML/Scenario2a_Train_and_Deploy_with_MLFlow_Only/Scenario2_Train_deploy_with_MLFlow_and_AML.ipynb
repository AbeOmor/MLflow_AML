{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 2: Train and deploy with MLFlow and AML\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)\tTrain baseline model and log / autolog with MLFlow and submit job with AML CLI/MLFLow CLI\r\n",
        "\r\n",
        "2)\tTest model locally with v2 CLI and manually validate results\r\n",
        "\r\n",
        "3)\tRegister the model from the run \r\n",
        "\r\n",
        "4)\t{Optional} Change the model stage to “Production” and discuss with team before deploying to production (**NOTE:** Not fully integrate in AML UI yet)\r\n",
        "    \r\n",
        "5)\tAfter user is satisfied with the model, deploy model on AML to an endpoint and use endpoint to predict all the result from a dataset. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move to AML by setting the tracking URI in the backend (not in my training code), and using MLFlow CLI. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az extension add -n ml -y "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az login"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "#Get MLFLow URI through the Azure ML CLI v2 and convert to string\n",
        "MLFLOW_TRACKING_URI = subprocess.run([\"az\", \"ml\", \"workspace\", \"show\", \"--query\", \"mlflow_tracking_uri\", \"-o\", \"tsv\"], stdout=subprocess.PIPE, text=True)\n",
        "MLFLOW_TRACKING_URI = str(MLFLOW_TRACKING_URI.stdout).strip()\n",
        "\n",
        "## Make sure the MLFLow URI looks something like this: \n",
        "## azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/<Sub-ID>/resourceGroups/<RG>/providers/Microsoft.MachineLearningServices/workspaces/<WS>\n",
        "print(\"MLFlow Tracking URI:\", MLFLOW_TRACKING_URI)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLFlow Tracking URI: azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourceGroups/osomorog/providers/Microsoft.MachineLearningServices/workspaces/mlflowworkspace\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1642628704944
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set the MLFLOW TRACKING URI\n",
        "import mlflow\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1642628708069
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train baseline model and log / autolog with MLFlow and submit job with MLFLow CLI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"USE_CONDA\": False}"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642628709343
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "local_env_run = mlflow.projects.run(uri=\"simple_project\", \n",
        "                                    parameters={\"alpha\":0.2},\n",
        "                                    experiment_name=\"Scenario2_project\",\n",
        "                                    backend = \"azureml\",\n",
        "                                    use_conda=True,\n",
        "                                    backend_config = backend_config, \n",
        "                                    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AzureMLProjectBackend: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2022/01/19 21:45:13 INFO mlflow.projects.utils: === Created directory /tmp/tmp7touvmv9 for downloading remote URIs passed to arguments of type 'path' ===\nWARNING: MLproject doesn't contain pip dependency azureml-mlflow. Adding it now...\nClass AzureMLSubmittedRun: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2022/01/19 21:45:41 INFO mlflow.projects: === Run (ID 'Scenario2_project_1642628714_741b107b') succeeded ===\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "19/01/2022 21:45:12 INFO azureml.mlflow: === Creating conda environment from Mlproject for local run ===\nRunId: Scenario2_project_1642628714_741b107b\nWeb View: https://ml.azure.com/runs/Scenario2_project_1642628714_741b107b?wsid=/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourcegroups/osomorog/workspaces/mlflowworkspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n\n[2022-01-19T21:45:18.287940] Entering context manager injector.\n[2022-01-19T21:45:18.885836] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['python train.py 0.2'])\nScript type = COMMAND\n[2022-01-19T21:45:18.888428] Command=python train.py 0.2\n[2022-01-19T21:45:18.888950] Entering Run History Context Manager.\n/home/azureuser/.azureml/envs/azureml_dd821c7bb5ac861b414886d5bea80815/lib/python3.6/site-packages/azureml/history/_tracking.py:186: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n  import mlflow\n[2022-01-19T21:45:20.465308] Command Working Directory=/tmp/azureml_runs/Scenario2_project_1642628714_741b107b\n[2022-01-19T21:45:20.465348] Starting Linux command : python train.py 0.2\nalpha value 0.2\nMean Squared Error is 3325.2946794678764\n[2022-01-19T21:45:38.017293] Command finished with return code 0\n\n\n[2022-01-19T21:45:38.018568] The experiment completed successfully. Finalizing run...\n[2022-01-19T21:45:38.018603] Start FinalizingInRunHistory\n[2022-01-19T21:45:38.018647] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 5110\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n1 items cleaning up...\nCleanup took 0.03792691230773926 seconds\n[2022-01-19T21:45:38.530143] Finished context manager injector.\n\nExecution Summary\n=================\nRunId: Scenario2_project_1642628714_741b107b\nWeb View: https://ml.azure.com/runs/Scenario2_project_1642628714_741b107b?wsid=/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourcegroups/osomorog/workspaces/mlflowworkspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642628741489
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download or retrieve the model from the run for testing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.entities import ViewType\n",
        "experiment_name=\"Scenario2_project\"\n",
        "current_experiment=mlflow.get_experiment_by_name(experiment_name)\n",
        "runs = mlflow.search_runs(experiment_ids=current_experiment.experiment_id, run_view_type=ViewType.ALL)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1642628741794
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_run_id = runs.tail(1)[\"run_id\"].tolist()[0]\r\n",
        "last_run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "'Scenario2_project_1642628714_741b107b'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1642628742193
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and Load Test Data from JSON"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.tracking.client import MlflowClient\n",
        "client = MlflowClient()\n",
        "client.download_artifacts(last_run_id,\"model/input_example.json\",\".\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/osomorog1/code/Users/osomorog/mlflow-new-test/Scenario2_Train_deploy_with_MLFlow_and_AML/Scenario2a_Train_and_Deploy_with_MLFlow_Only/model/input_example.json'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1642628742584
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "with open('model/input_example.json') as f:\r\n",
        "   sample_data = json.load(f)\r\n",
        "\r\n",
        "#columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\r\n",
        "print(sample_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'inputs': [[0.0126481372762872, 0.0506801187398187, 0.00241654245523897, 0.0563010619323185, 0.0273260502020124, 0.0171618818193638, 0.0412768238419757, -0.0394933828740919, 0.00371173823343597, 0.0734802269665584], [-0.107225631607358, -0.044641636506989, -0.0773415510119477, -0.0263278347173518, -0.0896299427450836, -0.0961978613484469, 0.0265502726256275, -0.076394503750001, -0.0425721049227942, -0.0052198044153011], [0.0271782910803654, 0.0506801187398187, -0.0353068801305926, 0.0322009670761646, -0.0112006298276192, 0.00150445872988718, -0.0102661054152432, -0.00259226199818282, -0.0149564750249113, -0.0507829804784829], [-0.00551455497881059, 0.0506801187398187, 0.00133873038135806, -0.0848566365108683, -0.0112006298276192, -0.0166581520539057, 0.0486400994501499, -0.0394933828740919, -0.0411803851880079, -0.0880619427119953], [0.0671362140415805, 0.0506801187398187, 0.0207393477112143, -0.00567061055493425, 0.0204462859110067, 0.0262431872112602, -0.0029028298070691, -0.00259226199818282, 0.00864028293306308, 0.00306440941436832]]}\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1642628742842
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"model\"\r\n",
        "artifact_uri = \"runs:/{}/{}\".format(last_run_id,model_path)\r\n",
        "model = mlflow.sklearn.load_model(artifact_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator Ridge from version 0.22.2.post1 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642628743915
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(sample_data[\"inputs\"])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "array([149.92210841,  99.36325181, 126.288127  ,  85.10695952,\n       151.26791908])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1642628744267
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register Model with MLFLow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"scenario2model\"\r\n",
        "mlflow.register_model(artifact_uri,model_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Registered model 'scenario2model' already exists. Creating a new version of this model...\n2022/01/19 21:45:45 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: scenario2model, version 7\nCreated version '7' of model 'scenario2model'.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<ModelVersion: creation_timestamp=1642628744963, current_stage='None', description='', last_updated_timestamp=1642628744963, name='scenario2model', run_id='Scenario2_project_1642628714_741b107b', run_link='', source='azureml://experiments/Scenario2_project/runs/Scenario2_project_1642628714_741b107b/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='7'>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1642628745231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Transistion Model to Production Stage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "client = MlflowClient()\r\n",
        "client.transition_model_version_stage(\r\n",
        "    name=model_name,\r\n",
        "    version=1,\r\n",
        "    stage=\"Production\"\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638588491686
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List Model details and get latest"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\r\n",
        "client = MlflowClient()\r\n",
        "query = \"name='{}'\".format(model_name)\r\n",
        "for mv in client.search_model_versions(query):\r\n",
        "    pprint(dict(mv), indent=4)\r\n",
        "\r\n",
        "\r\n",
        "latest_model_version = client.search_model_versions(query)[0].version"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{   'creation_timestamp': 1642628744963,\n    'current_stage': 'None',\n    'description': '',\n    'last_updated_timestamp': 1642628744963,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1642628714_741b107b',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1642628714_741b107b/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '7'}\n{   'creation_timestamp': 1642627217984,\n    'current_stage': 'None',\n    'description': '',\n    'last_updated_timestamp': 1642627217984,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1642626760_b653500c',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1642626760_b653500c/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '6'}\n{   'creation_timestamp': 1642621113918,\n    'current_stage': 'None',\n    'description': '',\n    'last_updated_timestamp': 1642621113918,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1642620928_833f911a',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1642620928_833f911a/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '5'}\n{   'creation_timestamp': 1642620467638,\n    'current_stage': 'None',\n    'description': '',\n    'last_updated_timestamp': 1642620467638,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1642620410_6c1500d7',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1642620410_6c1500d7/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '4'}\n{   'creation_timestamp': 1642196737170,\n    'current_stage': 'None',\n    'description': '',\n    'last_updated_timestamp': 1642196737170,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1638814400_6d76b34a',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1638814400_6d76b34a/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '3'}\n{   'creation_timestamp': 1638814541944,\n    'current_stage': 'None',\n    'description': '',\n    'last_updated_timestamp': 1638814541944,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1638814400_6d76b34a',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1638814400_6d76b34a/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '2'}\n{   'creation_timestamp': 1638588486086,\n    'current_stage': 'Production',\n    'description': '',\n    'last_updated_timestamp': 1638588487087,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1638586862_9ed4fdf5',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1638586862_9ed4fdf5/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '1'}\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642629225777
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy to AzureML's MIR with MLFLow\r\n",
        "- Endpoints are not fully supported with MLFlow deployment, there is a 1:1 relationship between deployment and endpoint. MLFlow needs to support the ability to deploy multiple models to the 1 endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.deployments import get_deploy_client\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# set the tracking uri as the deployment client\n",
        "client = get_deploy_client(mlflow.get_tracking_uri())\n",
        "\n",
        "# Retrieve model from registry\n",
        "model_name = model_name\n",
        "model_version = latest_model_version\n",
        "model_uri = 'models:/{}/{}'.format(model_name, model_version)\n",
        "\n",
        "# define the model path and the name is the service name\n",
        "# the model gets registered automatically and a name is autogenerated using the \"name\" parameter below \n",
        "# set the deployment config\n",
        "deploy_path = \"deployment_config_v2.json\"\n",
        "test_config = {'deploy-config-file': deploy_path}\n",
        "\n",
        "endpoint_name = \"mlflowscenario\"\n",
        "\n",
        "client.create_deployment(model_uri=model_uri,\n",
        "                         config=test_config,\n",
        "                         name=endpoint_name)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "{'id': '/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourceGroups/osomorog/providers/Microsoft.MachineLearningServices/workspaces/mlflowworkspace/onlineEndpoints/mlflowscenario',\n 'name': 'mlflowscenario',\n 'type': 'Microsoft.MachineLearningServices/workspaces/onlineEndpoints',\n 'properties': {'description': None,\n  'properties': {'azureml.mlflow_client_endpoint': 'True',\n   'azureml.onlineendpointid': '/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourcegroups/osomorog/providers/microsoft.machinelearningservices/workspaces/mlflowworkspace/onlineendpoints/mlflowscenario',\n   'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/providers/Microsoft.MachineLearningServices/locations/westus/mfeOperationsStatus/oe:25efd296-21b5-40a9-bcae-d2a9902eb623:1183fadf-cee1-4ec8-b8d9-c3a45ce37aff?api-version=2021-10-01'},\n  'scoringUri': 'https://mlflowscenario.westus.inference.ml.azure.com/score',\n  'swaggerUri': 'https://mlflowscenario.westus.inference.ml.azure.com/swagger.json',\n  'authMode': 'AMLToken',\n  'provisioningState': 'Succeeded',\n  'compute': None,\n  'allowPublicAccess': True,\n  'traffic': {'mlflowscenario': 100}},\n 'systemData': {'createdAt': '2022-01-19T21:54:50.4803911Z',\n  'createdBy': 'Abe Omorogbe',\n  'lastModifiedAt': '2022-01-19T22:02:34.7364682Z'},\n 'tags': {},\n 'location': 'westus',\n 'kind': 'Managed'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642629755258
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test endpoint with MLFlow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the [test json request](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models-online-endpoints?tabs=endpoint%2Cstudio#invoke-the-endpoint) and get access token to test your endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "with open('aml_endpoint_input_example.json') as f:\r\n",
        "   sample_endpoint_input = json.load(f)\r\n",
        "\r\n",
        "print(sample_endpoint_input)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'input_data': {'columns': ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data': [[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0], [10.0, 2.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0]], 'index': [0, 1]}}\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642629814515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\r\n",
        "\r\n",
        "rg = \"osomorog\"\r\n",
        "ws_name = \"mlflowworkspace\"\r\n",
        "#Get Access Token through the Azure ML CLI v2 and convert to string\r\n",
        "TOKEN = subprocess.run([\"az\", \"ml\", \"online-endpoint\", \"get-credentials\", \"--name\", endpoint_name, \"--resource-group\", rg, \"--workspace-name\", ws_name], stdout=subprocess.PIPE, text=True)\r\n",
        "TOKEN = json.loads(str(TOKEN.stdout).strip())\r\n",
        "\r\n",
        "print(\"Access Token:\", TOKEN['accessToken'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Access Token: eyJhbGciOiJSUzI1NiIsImtpZCI6IkI1OTdEQ0Q4QUIxN0MxNDEyQkIzMkZDOEIzRjc4M0JCOTY2QTFFMjQiLCJ0eXAiOiJKV1QifQ.eyJjYW5SZWZyZXNoIjoiRmFsc2UiLCJ3b3Jrc3BhY2VJZCI6IjI1ZWZkMjk2LTIxYjUtNDBhOS1iY2FlLWQyYTk5MDJlYjYyMyIsInRpZCI6IjMzZTAxOTIxLTRkNjQtNGY4Yy1hMDU1LTViZGFmZmQ1ZTMzZCIsIm9pZCI6ImZjNmJhZjU1LTZiYmItNDU0ZC1hYTIzLWUxNTgwY2NiOWJkYSIsImFjdGlvbnMiOiJbXCJNaWNyb3NvZnQuTWFjaGluZUxlYXJuaW5nU2VydmljZXMvd29ya3NwYWNlcy9vbmxpbmVFbmRwb2ludHMvc2NvcmUvYWN0aW9uXCJdIiwiZW5kcG9pbnROYW1lIjoibWxmbG93c2NlbmFyaW8iLCJzZXJ2aWNlSWQiOiJtbGZsb3dzY2VuYXJpbyIsImV4cCI6MTY0MjcxNjIyMCwiaXNzIjoiYXp1cmVtbCIsImF1ZCI6ImF6dXJlbWwifQ.Y8R65sqYwQDOcksx2u_8do__ogXaf8fI8TEttvGVp9LY8B4IJExKAaFsRMO7tJ6DpyYQShjyCFl7GhwLL0slRPRzaWP955s0-xqDzJms5YWRykKxT89CEKDOteEmVOOZI_b0xWYTBT-Fmvh3l58e82gXYsSbPc7JL9FgipKK9eFgX_URH8ZzDpoOfd1iHkXiO-oBNA6OQGcypwfCxV28JV5zYmdpYAvL43_dgNGgZ3A3uo023XKzyE9CqsnShzPbCA00jFyyGINic9O9-oWQkKOh4C58xtr8MIvcQeaETLPRsxrEkkJWtOdi2Hc_zexwlzIw0xlwD53C4dyGE7Iu3A\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642629821196
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find code snippet below, in the Endpoint UI in AzureML and navigate to the Consume Tab for the Endpoint you just deployed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = sample_endpoint_input\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'https://{}.westus.inference.ml.azure.com/score'.format(endpoint_name)\r\n",
        "access_token = TOKEN['accessToken']\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ access_token)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "b'[5438.7408136299955, 5955.792058496274]'\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1642629848448
        }
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernel_info": {
      "name": "azureml_py38_pytorch"
    },
    "kernelspec": {
      "name": "azureml_py38_pytorch",
      "language": "python",
      "display_name": "Python 3.8 - PyTorch"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}