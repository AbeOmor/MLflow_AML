{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 2: Train and deploy with MLFlow and AML\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc: https://microsoft-my.sharepoint.com/:w:/p/osomorog/Ed7l1SLKac9Irz_PY-XnXaQB90-WeAosazcQOT24PRd3-g?e=hKS09V "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move to AML by setting the tracking URI in the backend (not in my training code), and using MLFlow CLI. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az extension add -n ml -y "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[K - Searching ..\r\u001b[93mExtension 'ml' is already installed.\u001b[0m\r\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!az login"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "#Get MLFLow UI through the Azure ML CLI v2 and convert to string\n",
        "MLFLOW_TRACKING_URI = subprocess.run([\"az\", \"ml\", \"workspace\", \"show\", \"--query\", \"mlflow_tracking_uri\", \"-o\", \"tsv\"], stdout=subprocess.PIPE, text=True)\n",
        "MLFLOW_TRACKING_URI = str(MLFLOW_TRACKING_URI.stdout).strip()\n",
        "\n",
        "## Make sure the MLFLow URI looks something like this: \n",
        "## azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/<Sub-ID>/resourceGroups/<RG>/providers/Microsoft.MachineLearningServices/workspaces/<WS>\n",
        "print(\"MLFlow Tracking URI:\", MLFLOW_TRACKING_URI)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING: Command group 'ml workspace' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLFlow Tracking URI: azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourceGroups/osomorog/providers/Microsoft.MachineLearningServices/workspaces/mlflowworkspace\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1638586795117
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set the MLFLOW TRACKING URI\n",
        "import mlflow\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1638586797163
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train baseline model and log / autolog with MLFlow and submit job with MLFLow CLI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"USE_CONDA\": False}"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638586798315
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "local_env_run = mlflow.projects.run(uri=\"simple_project\", \n",
        "                                    parameters={\"alpha\":0.2},\n",
        "                                    experiment_name=\"Scenario2_project\",\n",
        "                                    backend = \"azureml\",\n",
        "                                    use_conda=True,\n",
        "                                    backend_config = backend_config, \n",
        "                                    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AzureMLProjectBackend: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2021/12/04 03:01:01 INFO mlflow.projects.utils: === Created directory /tmp/tmp0sp5c_f0 for downloading remote URIs passed to arguments of type 'path' ===\nWARNING: MLproject doesn't contain pip dependency azureml-mlflow. Adding it now...\nClass AzureMLSubmittedRun: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2021/12/04 03:01:28 INFO mlflow.projects: === Run (ID 'Scenario2_project_1638586862_9ed4fdf5') succeeded ===\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "04/12/2021 02:59:58 INFO azureml.mlflow: === Creating conda environment from Mlproject for local run ===\nRunId: Scenario2_project_1638586862_9ed4fdf5\nWeb View: https://ml.azure.com/runs/Scenario2_project_1638586862_9ed4fdf5?wsid=/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourcegroups/osomorog/workspaces/mlflowworkspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n\n[2021-12-04T03:01:10.938457] Entering context manager injector.\n[2021-12-04T03:01:11.302762] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['python train.py 0.2'])\nScript type = COMMAND\n[2021-12-04T03:01:11.304670] Command=python train.py 0.2\n[2021-12-04T03:01:11.304874] Entering Run History Context Manager.\n[2021-12-04T03:01:12.452741] Command Working Directory=/tmp/azureml_runs/Scenario2_project_1638586862_9ed4fdf5\n[2021-12-04T03:01:12.452764] Starting Linux command : python train.py 0.2\nAlready registered authentication for run id: Scenario2_project_1638586862_9ed4fdf5\nalpha value 0.2\nMean Squared Error is 3325.294679467877\n[2021-12-04T03:01:24.896620] Command finished with return code 0\n\n\n[2021-12-04T03:01:24.896970] The experiment completed successfully. Finalizing run...\n[2021-12-04T03:01:24.896989] Start FinalizingInRunHistory\n[2021-12-04T03:01:24.897022] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 28206\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n1 items cleaning up...\nCleanup took 0.03725576400756836 seconds\n[2021-12-04T03:01:25.485609] Finished context manager injector.\n\nExecution Summary\n=================\nRunId: Scenario2_project_1638586862_9ed4fdf5\nWeb View: https://ml.azure.com/runs/Scenario2_project_1638586862_9ed4fdf5?wsid=/subscriptions/95a911b6-47f7-4a8b-be9b-c1c2bf56579b/resourcegroups/osomorog/workspaces/mlflowworkspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638586890387
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download or retrieve the model from the run for testing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.entities import ViewType\n",
        "experiment_name=\"Scenario2_project\"\n",
        "current_experiment=mlflow.get_experiment_by_name(experiment_name)\n",
        "runs = mlflow.search_runs(experiment_ids=current_experiment.experiment_id, run_view_type=ViewType.ALL)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1638586932931
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_run_id = runs.tail(1)[\"run_id\"].tolist()[0]\r\n",
        "last_run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "'Scenario2_project_1638586862_9ed4fdf5'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1638586951909
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.tracking.client import MlflowClient\n",
        "client = MlflowClient()\n",
        "client.download_artifacts(last_run_id,\"model/input_example.json\",\".\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/osomorog4/code/Users/osomorog/MLFlow_Scenarios/Scenario2/model/input_example.json'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1638587035685
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "with open('model/input_example.json') as f:\r\n",
        "   sample_data = json.load(f)\r\n",
        "\r\n",
        "#columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\r\n",
        "print(sample_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'inputs': [[0.0126481372762872, 0.0506801187398187, 0.00241654245523897, 0.0563010619323185, 0.0273260502020124, 0.0171618818193638, 0.0412768238419757, -0.0394933828740919, 0.00371173823343597, 0.0734802269665584], [-0.107225631607358, -0.044641636506989, -0.0773415510119477, -0.0263278347173518, -0.0896299427450836, -0.0961978613484469, 0.0265502726256275, -0.076394503750001, -0.0425721049227942, -0.0052198044153011], [0.0271782910803654, 0.0506801187398187, -0.0353068801305926, 0.0322009670761646, -0.0112006298276192, 0.00150445872988718, -0.0102661054152432, -0.00259226199818282, -0.0149564750249113, -0.0507829804784829], [-0.00551455497881059, 0.0506801187398187, 0.00133873038135806, -0.0848566365108683, -0.0112006298276192, -0.0166581520539057, 0.0486400994501499, -0.0394933828740919, -0.0411803851880079, -0.0880619427119953], [0.0671362140415805, 0.0506801187398187, 0.0207393477112143, -0.00567061055493425, 0.0204462859110067, 0.0262431872112602, -0.0029028298070691, -0.00259226199818282, 0.00864028293306308, 0.00306440941436832]]}\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1638587472181
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"model\"\r\n",
        "artifact_uri = \"runs:/{}/{}\".format(last_run_id,model_path)\r\n",
        "model = mlflow.sklearn.load_model(artifact_uri)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638587285741
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(sample_data[\"inputs\"])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "array([149.92210841,  99.36325181, 126.288127  ,  85.10695952,\n       151.26791908])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1638587491360
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register Model with MLFLow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.register_model(artifact_uri,\"scenario2model\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Successfully registered model 'scenario2model'.\n2021/12/04 03:28:06 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: scenario2model, version 1\nCreated version '1' of model 'scenario2model'.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "<ModelVersion: creation_timestamp=1638588486086, current_stage='None', description='', last_updated_timestamp=1638588486086, name='scenario2model', run_id='Scenario2_project_1638586862_9ed4fdf5', run_link='', source='azureml://experiments/Scenario2_project/runs/Scenario2_project_1638586862_9ed4fdf5/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1638588489490
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Transistion Model to Production Stage"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "client = MlflowClient()\r\n",
        "client.transition_model_version_stage(\r\n",
        "    name=\"scenario2model\",\r\n",
        "    version=1,\r\n",
        "    stage=\"Production\"\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "<ModelVersion: creation_timestamp=1638588486086, current_stage='Production', description='', last_updated_timestamp=1638588487087, name='scenario2model', run_id='Scenario2_project_1638586862_9ed4fdf5', run_link='', source='azureml://experiments/Scenario2_project/runs/Scenario2_project_1638586862_9ed4fdf5/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1638588491686
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List Model details"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\r\n",
        "client = MlflowClient()\r\n",
        "for mv in client.search_model_versions(\"name='scenario2model'\"):\r\n",
        "    pprint(dict(mv), indent=4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{   'creation_timestamp': 1638588486086,\n    'current_stage': 'Production',\n    'description': '',\n    'last_updated_timestamp': 1638588487087,\n    'name': 'scenario2model',\n    'run_id': 'Scenario2_project_1638586862_9ed4fdf5',\n    'run_link': '',\n    'source': 'azureml://experiments/Scenario2_project/runs/Scenario2_project_1638586862_9ed4fdf5/artifacts/model',\n    'status': 'READY',\n    'status_message': '',\n    'tags': {},\n    'user_id': '',\n    'version': '1'}\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638588493857
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy to AzureML's MIR with MLFLow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.deployments import get_deploy_client\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from azureml.core import Workspace;\n",
        "mlflow.set_tracking_uri(Workspace.from_config().get_mlflow_tracking_uri())\n",
        "# set the tracking uri as the deployment client\n",
        "client = get_deploy_client(mlflow.get_tracking_uri())\n",
        "\n",
        "# set the model path \n",
        "# model_path = \"model\"\n",
        "# run_id= \"13c5faef-788f-439d-ba6c-cb8d280e708d\"\n",
        "\n",
        "# Retrieve model from registry\n",
        "model_name = \"scenario2model\"\n",
        "model_version = 1\n",
        "model_uri = 'models:/{}/{}'.format(model_name, model_version)\n",
        "\n",
        "# define the model path and the name is the service name\n",
        "# the model gets registered automatically and a name is autogenerated using the \"name\" parameter below \n",
        "# set the deployment config\n",
        "deploy_path = \"deployment_config_v2.json\"\n",
        "test_config = {'deploy-config-file': deploy_path}\n",
        "\n",
        "client.create_deployment(model_uri=model_uri,\n",
        "                         config=test_config,\n",
        "                         name=\"mlflowscenario2\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test endpoint with MLFlow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find code snippet below, in the Endpoint UI in AzureML and navigate to the Consume Tab for the Endpoint you just deployed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = sample_data\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'https://mlflowscenario2.westus.inference.ml.azure.com/score'\r\n",
        "api_key = '' # Replace this with the API key for the web service\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}